# üéØ Roteiro Pr√°tico: Exporta√ß√£o e An√°lise de Dados Locust

## Informa√ß√µes do Roteiro
- **Disciplina**: Avalia√ß√£o de Desempenho de Sistemas
- **Objetivo**: Aprender a exportar, analisar e interpretar resultados de testes de performance
- **Dura√ß√£o estimada**: 3-4 horas
- **Pr√©-requisitos**:
  - Python 3.8+
  - Locust instalado
  - Conhecimento b√°sico de pandas
  - Ter completado testes b√°sicos com Locust

---

## üìã Parte 1: Exporta√ß√£o B√°sica de Dados (30 min)

### Exerc√≠cio 1.1: Exporta√ß√£o via Interface Web

**Objetivo**: Aprender a exportar dados atrav√©s da interface gr√°fica do Locust.

**Passos:**

1. Crie um locustfile simples (`locustfile_basico.py`):

```python
from locust import HttpUser, task, between

class UsuarioBasico(HttpUser):
    wait_time = between(1, 3)

    @task(3)
    def pagina_inicial(self):
        self.client.get("/")

    @task(2)
    def sobre(self):
        self.client.get("/about")

    @task(1)
    def contato(self):
        self.client.get("/contact")
```

2. Execute o Locust com interface web:

```bash
locust -f locustfile_basico.py --host=https://httpbin.org
```

3. Acesse `http://localhost:8089`

4. Configure o teste:
   - Usu√°rios: 50
   - Spawn rate: 10
   - Execute por 3 minutos

5. Ap√≥s o teste, clique em "Download Data" e baixe todos os arquivos dispon√≠veis

**Resultado esperado:**
- `stats.csv`
- `stats_history.csv`
- `failures.csv`
- `report_*.html`

**Quest√µes para reflex√£o:**
1. Quantas requisi√ß√µes foram feitas no total?
2. Qual endpoint teve o maior tempo de resposta m√©dio?
3. Houve alguma falha durante o teste?

---

### Exerc√≠cio 1.2: Exporta√ß√£o via CLI (Headless)

**Objetivo**: Automatizar a exporta√ß√£o de dados sem interface gr√°fica.

**Passos:**

1. Crie uma pasta para organizar os resultados:

```bash
mkdir -p resultados/teste_$(date +%Y%m%d_%H%M%S)
```

2. Execute o Locust em modo headless com exporta√ß√£o autom√°tica:

```bash
locust -f locustfile_basico.py \
  --host=https://httpbin.org \
  -u 100 \
  --spawn-rate 20 \
  --run-time 5m \
  --headless \
  --csv=resultados/teste_cli \
  --html=resultados/teste_cli.html \
  --loglevel=INFO
```

3. Verifique os arquivos gerados:

```bash
ls -lh resultados/
```

**Resultado esperado:**
- M√∫ltiplos arquivos CSV com prefixo `teste_cli_`
- Arquivo HTML `teste_cli.html`
- Teste executado sem intera√ß√£o manual

**Quest√µes para reflex√£o:**
1. Qual a vantagem de usar o modo headless?
2. Em que situa√ß√µes voc√™ usaria cada m√©todo (web vs CLI)?

---

## üìä Parte 2: An√°lise B√°sica com Pandas (45 min)

### Exerc√≠cio 2.1: Leitura e Inspe√ß√£o de Dados

**Objetivo**: Carregar e entender a estrutura dos dados exportados.

Crie um script `analise_basica.py`:

```python
import pandas as pd
import numpy as np

# Carregar dados
print("=" * 80)
print("AN√ÅLISE B√ÅSICA DE DADOS LOCUST")
print("=" * 80)

# 1. Carregar stats.csv
stats_df = pd.read_csv('resultados/teste_cli_stats.csv')

print("\nüìÅ Estrutura do DataFrame (stats.csv):")
print(stats_df.info())

print("\nüìã Primeiras linhas:")
print(stats_df.head())

print("\nüìä Estat√≠sticas descritivas:")
print(stats_df.describe())

# 2. An√°lise de colunas importantes
print("\nüîç Colunas dispon√≠veis:")
for col in stats_df.columns:
    print(f"  - {col}")

# 3. Verificar valores ausentes
print("\n‚ö†Ô∏è  Valores ausentes por coluna:")
print(stats_df.isnull().sum())
```

**Execute:**

```bash
python analise_basica.py
```

**Tarefa:**
Identifique e anote:
1. Quantas colunas existem no DataFrame?
2. Quais colunas cont√™m informa√ß√µes de tempo de resposta?
3. Como as falhas s√£o representadas?

---

### Exerc√≠cio 2.2: C√°lculo de M√©tricas Principais

**Objetivo**: Calcular e interpretar m√©tricas de performance.

Adicione ao seu script `analise_basica.py`:

```python
# 4. M√©tricas principais
print("\n" + "=" * 80)
print("M√âTRICAS PRINCIPAIS")
print("=" * 80)

# Total de requisi√ß√µes
total_requisicoes = stats_df['Request Count'].sum()
print(f"\nüìà Total de requisi√ß√µes: {total_requisicoes:,}")

# Total de falhas
total_falhas = stats_df['Failure Count'].sum()
print(f"‚ùå Total de falhas: {total_falhas:,}")

# Taxa de erro
taxa_erro = (total_falhas / total_requisicoes * 100) if total_requisicoes > 0 else 0
print(f"üìä Taxa de erro geral: {taxa_erro:.2f}%")

# Tempo de resposta m√©dio
tempo_medio_geral = stats_df['Average Response Time'].mean()
print(f"‚è±Ô∏è  Tempo de resposta m√©dio: {tempo_medio_geral:.2f}ms")

# P95 e P99
p95_geral = stats_df['95%'].mean()
p99_geral = stats_df['99%'].mean()
print(f"üìä P95 m√©dio: {p95_geral:.2f}ms")
print(f"üìä P99 m√©dio: {p99_geral:.2f}ms")

# 5. An√°lise por endpoint
print("\n" + "=" * 80)
print("AN√ÅLISE POR ENDPOINT")
print("=" * 80)

for idx, row in stats_df.iterrows():
    if row['Name'] != 'Aggregated':
        taxa_erro_endpoint = (row['Failure Count'] / row['Request Count'] * 100) if row['Request Count'] > 0 else 0

        print(f"\nüîπ {row['Name']}")
        print(f"   Requisi√ß√µes: {row['Request Count']:,}")
        print(f"   Falhas: {row['Failure Count']:,}")
        print(f"   Taxa de erro: {taxa_erro_endpoint:.2f}%")
        print(f"   Tempo m√©dio: {row['Average Response Time']:.2f}ms")
        print(f"   P50 (mediana): {row['50%']:.2f}ms")
        print(f"   P95: {row['95%']:.2f}ms")
        print(f"   P99: {row['99%']:.2f}ms")
        print(f"   Min: {row['Min Response Time']:.2f}ms")
        print(f"   Max: {row['Max Response Time']:.2f}ms")
```

**Tarefa de an√°lise:**
Responda com base nos resultados:
1. Qual endpoint teve o melhor desempenho? Por qu√™?
2. Qual endpoint teve o pior desempenho? Por qu√™?
3. A taxa de erro est√° dentro do aceit√°vel (< 0.1%)?
4. H√° grande diferen√ßa entre P50 e P99? O que isso indica?

---

### Exerc√≠cio 2.3: An√°lise de Evolu√ß√£o Temporal

**Objetivo**: Entender como as m√©tricas evolu√≠ram durante o teste.

Crie um novo script `analise_temporal.py`:

```python
import pandas as pd
import matplotlib.pyplot as plt

# Carregar hist√≥rico
history_df = pd.read_csv('resultados/teste_cli_stats_history.csv')

print("=" * 80)
print("AN√ÅLISE TEMPORAL")
print("=" * 80)

# Converter timestamp
history_df['Timestamp'] = pd.to_datetime(history_df['Timestamp'], unit='s')

print(f"\nüìÖ In√≠cio do teste: {history_df['Timestamp'].min()}")
print(f"üìÖ Fim do teste: {history_df['Timestamp'].max()}")
print(f"‚è±Ô∏è  Dura√ß√£o total: {history_df['Timestamp'].max() - history_df['Timestamp'].min()}")

# Estat√≠sticas ao longo do tempo
print("\nüìä Evolu√ß√£o das m√©tricas:")
print(history_df[['Timestamp', 'User Count', 'Total Request Count',
                  'Total Average Response Time', 'Total Requests/s']].tail(10))

# Identificar tend√™ncias
print("\nüìà An√°lise de tend√™ncias:")
tempo_inicio = history_df['Total Average Response Time'].iloc[:5].mean()
tempo_fim = history_df['Total Average Response Time'].iloc[-5:].mean()
variacao_pct = ((tempo_fim - tempo_inicio) / tempo_inicio * 100)

print(f"   Tempo m√©dio no in√≠cio: {tempo_inicio:.2f}ms")
print(f"   Tempo m√©dio no fim: {tempo_fim:.2f}ms")
print(f"   Varia√ß√£o: {variacao_pct:+.2f}%")

if variacao_pct > 10:
    print("   ‚ö†Ô∏è  ATEN√á√ÉO: Sistema apresentou degrada√ß√£o significativa")
elif variacao_pct < -10:
    print("   ‚úÖ Sistema melhorou performance (poss√≠vel efeito de cache)")
else:
    print("   ‚úÖ Sistema manteve performance est√°vel")
```

**Execute e analise:**

```bash
python analise_temporal.py
```

**Quest√µes para reflex√£o:**
1. O sistema manteve performance est√°vel ao longo do teste?
2. Houve degrada√ß√£o? Em que momento?
3. O que pode ter causado varia√ß√µes na performance?

---

## üìà Parte 3: Visualiza√ß√£o de Dados (45 min)

### Exerc√≠cio 3.1: Gr√°ficos B√°sicos

**Objetivo**: Criar visualiza√ß√µes para facilitar a interpreta√ß√£o dos dados.

Crie o script `visualizacao_basica.py`:

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Configurar estilo
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (14, 10)

# Carregar dados
stats_df = pd.read_csv('resultados/teste_cli_stats.csv')
history_df = pd.read_csv('resultados/teste_cli_stats_history.csv')
history_df['Timestamp'] = pd.to_datetime(history_df['Timestamp'], unit='s')

# Filtrar apenas endpoints (sem total)
endpoints_df = stats_df[stats_df['Name'] != 'Aggregated'].copy()

# Criar figura com 4 subplots
fig, axes = plt.subplots(2, 2, figsize=(16, 12))
fig.suptitle('An√°lise de Performance - Teste Locust', fontsize=16, fontweight='bold')

# 1. Tempo de Resposta por Endpoint
ax1 = axes[0, 0]
endpoints = endpoints_df['Name'].values
tempos = endpoints_df['Average Response Time'].values
bars = ax1.barh(endpoints, tempos, color='steelblue')
ax1.set_xlabel('Tempo de Resposta M√©dio (ms)')
ax1.set_title('Tempo de Resposta por Endpoint')
ax1.grid(axis='x', alpha=0.3)

# Adicionar valores nas barras
for i, bar in enumerate(bars):
    width = bar.get_width()
    ax1.text(width, bar.get_y() + bar.get_height()/2,
             f'{width:.0f}ms', ha='left', va='center', fontweight='bold')

# 2. Taxa de Erro por Endpoint
ax2 = axes[0, 1]
endpoints_df['Taxa_Erro'] = (endpoints_df['Failure Count'] /
                             endpoints_df['Request Count'] * 100)
taxa_erro = endpoints_df['Taxa_Erro'].values
colors_erro = ['red' if x > 1 else 'orange' if x > 0.1 else 'green'
               for x in taxa_erro]
bars = ax2.barh(endpoints, taxa_erro, color=colors_erro)
ax2.set_xlabel('Taxa de Erro (%)')
ax2.set_title('Taxa de Erro por Endpoint')
ax2.grid(axis='x', alpha=0.3)

# 3. Evolu√ß√£o do Tempo de Resposta
ax3 = axes[1, 0]
ax3.plot(history_df['Timestamp'], history_df['Total Average Response Time'],
         marker='o', linewidth=2, markersize=3, label='Tempo M√©dio', color='blue')
ax3.fill_between(history_df['Timestamp'],
                 history_df['Total Average Response Time'],
                 alpha=0.3, color='blue')
ax3.set_xlabel('Tempo')
ax3.set_ylabel('Tempo de Resposta (ms)')
ax3.set_title('Evolu√ß√£o do Tempo de Resposta')
ax3.legend()
ax3.grid(True, alpha=0.3)
plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45)

# 4. RPS e Usu√°rios ao Longo do Tempo
ax4 = axes[1, 1]
ax4_twin = ax4.twinx()
line1 = ax4.plot(history_df['Timestamp'], history_df['Total Requests/s'],
                 marker='o', linewidth=2, markersize=3, label='RPS', color='green')
line2 = ax4_twin.plot(history_df['Timestamp'], history_df['User Count'],
                      marker='s', linewidth=2, markersize=3, label='Usu√°rios',
                      color='orange')
ax4.set_xlabel('Tempo')
ax4.set_ylabel('Requisi√ß√µes por Segundo', color='green')
ax4_twin.set_ylabel('N√∫mero de Usu√°rios', color='orange')
ax4.set_title('RPS e Usu√°rios Ativos')
ax4.grid(True, alpha=0.3)
plt.setp(ax4.xaxis.get_majorticklabels(), rotation=45)

# Combinar legendas
lines = line1 + line2
labels = [l.get_label() for l in lines]
ax4.legend(lines, labels, loc='upper left')

plt.tight_layout()
plt.savefig('resultados/analise_performance.png', dpi=300, bbox_inches='tight')
print("‚úÖ Gr√°fico salvo: resultados/analise_performance.png")
plt.show()
```

**Execute:**

```bash
python visualizacao_basica.py
```

**Tarefa:**
Analise os gr√°ficos gerados e responda:
1. Qual padr√£o voc√™ observa na evolu√ß√£o do tempo de resposta?
2. A taxa de RPS foi constante ou variou?
3. H√° correla√ß√£o entre n√∫mero de usu√°rios e tempo de resposta?

---

### Exerc√≠cio 3.2: Gr√°fico de Percentis

**Objetivo**: Visualizar a distribui√ß√£o de tempos de resposta.

Adicione ao script `visualizacao_basica.py`:

```python
# Gr√°fico adicional: Distribui√ß√£o de Percentis
fig2, ax = plt.subplots(figsize=(12, 6))

percentis = ['50%', '66%', '75%', '80%', '90%', '95%', '99%']
x = range(len(endpoints))
width = 0.12

for i, percentil in enumerate(percentis):
    if percentil in endpoints_df.columns:
        valores = endpoints_df[percentil].values
        offset = (i - len(percentis)/2) * width
        ax.bar([p + offset for p in x], valores, width,
               label=f'P{percentil.replace("%", "")}', alpha=0.8)

ax.set_xlabel('Endpoints')
ax.set_ylabel('Tempo de Resposta (ms)')
ax.set_title('Distribui√ß√£o de Percentis por Endpoint')
ax.set_xticks(x)
ax.set_xticklabels(endpoints, rotation=45, ha='right')
ax.legend()
ax.grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.savefig('resultados/distribuicao_percentis.png', dpi=300, bbox_inches='tight')
print("‚úÖ Gr√°fico de percentis salvo: resultados/distribuicao_percentis.png")
plt.show()
```

---

## üî¨ Parte 4: An√°lise Avan√ßada (60 min)

### Exerc√≠cio 4.1: Compara√ß√£o de M√∫ltiplos Testes

**Objetivo**: Comparar resultados de diferentes execu√ß√µes de teste.

1. Execute 3 testes diferentes:

```bash
# Teste 1: Baixa carga
locust -f locustfile_basico.py --host=https://httpbin.org \
  -u 50 --spawn-rate 10 --run-time 3m --headless \
  --csv=resultados/teste_baixa_carga --html=resultados/teste_baixa_carga.html

# Teste 2: M√©dia carga
locust -f locustfile_basico.py --host=https://httpbin.org \
  -u 150 --spawn-rate 30 --run-time 3m --headless \
  --csv=resultados/teste_media_carga --html=resultados/teste_media_carga.html

# Teste 3: Alta carga
locust -f locustfile_basico.py --host=https://httpbin.org \
  -u 300 --spawn-rate 50 --run-time 3m --headless \
  --csv=resultados/teste_alta_carga --html=resultados/teste_alta_carga.html
```

2. Crie o script `comparacao_testes.py`:

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

def carregar_teste(nome, arquivo_csv):
    """Carrega dados de um teste e retorna m√©tricas principais"""
    df = pd.read_csv(arquivo_csv)

    # Filtrar linha agregada
    total_row = df[df['Name'] == 'Aggregated']

    if len(total_row) > 0:
        total_row = total_row.iloc[0]
        return {
            'Nome': nome,
            'Requisi√ß√µes': total_row['Request Count'],
            'Falhas': total_row['Failure Count'],
            'Taxa_Erro_%': (total_row['Failure Count'] / total_row['Request Count'] * 100) if total_row['Request Count'] > 0 else 0,
            'Tempo_M√©dio_ms': total_row['Average Response Time'],
            'P50_ms': total_row['50%'],
            'P95_ms': total_row['95%'],
            'P99_ms': total_row['99%'],
            'RPS': total_row['Requests/s']
        }
    return None

# Carregar todos os testes
testes = [
    carregar_teste('Baixa Carga (50u)', 'resultados/teste_baixa_carga_stats.csv'),
    carregar_teste('M√©dia Carga (150u)', 'resultados/teste_media_carga_stats.csv'),
    carregar_teste('Alta Carga (300u)', 'resultados/teste_alta_carga_stats.csv')
]

# Criar DataFrame comparativo
df_comparacao = pd.DataFrame(testes)
df_comparacao.set_index('Nome', inplace=True)

print("=" * 80)
print("COMPARA√á√ÉO ENTRE TESTES")
print("=" * 80)
print(df_comparacao.to_string())
print("\n")

# An√°lise de impacto da carga
print("=" * 80)
print("AN√ÅLISE DE IMPACTO DA CARGA")
print("=" * 80)

baixa = df_comparacao.loc['Baixa Carga (50u)']
alta = df_comparacao.loc['Alta Carga (300u)']

print(f"\nAumento de carga: {(alta['Requisi√ß√µes'] / baixa['Requisi√ß√µes']):.1f}x")
print(f"Impacto no tempo m√©dio: {((alta['Tempo_M√©dio_ms'] - baixa['Tempo_M√©dio_ms']) / baixa['Tempo_M√©dio_ms'] * 100):+.1f}%")
print(f"Impacto no P95: {((alta['P95_ms'] - baixa['P95_ms']) / baixa['P95_ms'] * 100):+.1f}%")
print(f"Impacto no P99: {((alta['P99_ms'] - baixa['P99_ms']) / baixa['P99_ms'] * 100):+.1f}%")
print(f"Varia√ß√£o na taxa de erro: {(alta['Taxa_Erro_%'] - baixa['Taxa_Erro_%']):+.2f} pontos percentuais")

# Visualiza√ß√µes
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle('Compara√ß√£o de Testes de Carga', fontsize=16, fontweight='bold')

# 1. Tempos de Resposta
ax1 = axes[0, 0]
df_comparacao[['Tempo_M√©dio_ms', 'P95_ms', 'P99_ms']].plot(kind='bar', ax=ax1)
ax1.set_title('Tempos de Resposta por N√≠vel de Carga')
ax1.set_ylabel('Tempo (ms)')
ax1.set_xlabel('')
ax1.legend(['M√©dio', 'P95', 'P99'])
ax1.grid(axis='y', alpha=0.3)
plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')

# 2. Taxa de Erro
ax2 = axes[0, 1]
df_comparacao['Taxa_Erro_%'].plot(kind='bar', ax=ax2, color='red', alpha=0.7)
ax2.set_title('Taxa de Erro por N√≠vel de Carga')
ax2.set_ylabel('Taxa de Erro (%)')
ax2.set_xlabel('')
ax2.grid(axis='y', alpha=0.3)
plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')

# 3. RPS
ax3 = axes[1, 0]
df_comparacao['RPS'].plot(kind='bar', ax=ax3, color='green', alpha=0.7)
ax3.set_title('Requisi√ß√µes por Segundo')
ax3.set_ylabel('RPS')
ax3.set_xlabel('')
ax3.grid(axis='y', alpha=0.3)
plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45, ha='right')

# 4. Total de Requisi√ß√µes
ax4 = axes[1, 1]
df_comparacao['Requisi√ß√µes'].plot(kind='bar', ax=ax4, color='blue', alpha=0.7)
ax4.set_title('Total de Requisi√ß√µes Processadas')
ax4.set_ylabel('N√∫mero de Requisi√ß√µes')
ax4.set_xlabel('')
ax4.grid(axis='y', alpha=0.3)
plt.setp(ax4.xaxis.get_majorticklabels(), rotation=45, ha='right')

plt.tight_layout()
plt.savefig('resultados/comparacao_testes.png', dpi=300, bbox_inches='tight')
print("\n‚úÖ Gr√°fico de compara√ß√£o salvo: resultados/comparacao_testes.png")
plt.show()
```

**Execute:**

```bash
python comparacao_testes.py
```

**Quest√µes de an√°lise:**
1. O tempo de resposta aumentou linearmente com a carga?
2. Em que ponto o sistema come√ßou a apresentar degrada√ß√£o significativa?
3. A taxa de erro aumentou com a carga? Por qu√™?

---

### Exerc√≠cio 4.2: An√°lise de Outliers

**Objetivo**: Identificar requisi√ß√µes an√¥malas que afetam a performance.

Crie o script `analise_outliers.py`:

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Carregar dados
stats_df = pd.read_csv('resultados/teste_alta_carga_stats.csv')
endpoints_df = stats_df[stats_df['Name'] != 'Aggregated'].copy()

print("=" * 80)
print("AN√ÅLISE DE OUTLIERS")
print("=" * 80)

for idx, row in endpoints_df.iterrows():
    endpoint = row['Name']
    min_time = row['Min Response Time']
    avg_time = row['Average Response Time']
    max_time = row['Max Response Time']
    p99 = row['99%']

    # Calcular amplitude
    amplitude = max_time - min_time
    amplitude_p99_min = p99 - min_time

    # Calcular coeficiente de varia√ß√£o
    # Nota: precisar√≠amos do desvio padr√£o real, mas vamos estimar
    cv_estimado = (max_time - min_time) / avg_time

    print(f"\nüîπ {endpoint}")
    print(f"   Min: {min_time:.2f}ms")
    print(f"   M√©dia: {avg_time:.2f}ms")
    print(f"   P99: {p99:.2f}ms")
    print(f"   Max: {max_time:.2f}ms")
    print(f"   Amplitude total: {amplitude:.2f}ms")
    print(f"   Amplitude P99-Min: {amplitude_p99_min:.2f}ms")
    print(f"   Coef. Varia√ß√£o estimado: {cv_estimado:.2f}")

    # Detectar outliers significativos
    if max_time > (p99 * 2):
        print(f"   ‚ö†Ô∏è  OUTLIER DETECTADO: M√°ximo √© {(max_time/p99):.1f}x maior que P99")

    # Verificar consist√™ncia
    if amplitude > (avg_time * 5):
        print(f"   ‚ö†Ô∏è  ALTA VARIABILIDADE: Amplitude √© {(amplitude/avg_time):.1f}x a m√©dia")

    # Avaliar distribui√ß√£o
    ratio_p99_avg = p99 / avg_time
    if ratio_p99_avg > 2:
        print(f"   ‚ö†Ô∏è  CAUDA LONGA: P99 √© {ratio_p99_avg:.1f}x a m√©dia (distribui√ß√£o assim√©trica)")

# Visualiza√ß√£o de box plot
fig, ax = plt.subplots(figsize=(12, 6))

endpoints = endpoints_df['Name'].values
data_for_boxplot = []

for idx, row in endpoints_df.iterrows():
    # Simular distribui√ß√£o baseada nos percentis
    # (em um caso real, voc√™ teria os dados brutos)
    data_for_boxplot.append([
        row['Min Response Time'],
        row['50%'],
        row['Average Response Time'],
        row['95%'],
        row['99%'],
        row['Max Response Time']
    ])

# Criar gr√°fico
positions = range(len(endpoints))
for i, (endpoint, data) in enumerate(zip(endpoints, data_for_boxplot)):
    # Plotar linha mostrando range
    ax.plot([i, i], [data[0], data[5]], 'k-', linewidth=1, alpha=0.3)
    # Min
    ax.plot(i, data[0], 'go', markersize=8, label='Min' if i == 0 else '')
    # P50
    ax.plot(i, data[1], 'bo', markersize=8, label='P50' if i == 0 else '')
    # Avg
    ax.plot(i, data[2], 'yo', markersize=8, label='Avg' if i == 0 else '')
    # P95
    ax.plot(i, data[3], 'o', color='orange', markersize=8, label='P95' if i == 0 else '')
    # P99
    ax.plot(i, data[4], 'ro', markersize=8, label='P99' if i == 0 else '')
    # Max
    ax.plot(i, data[5], 'mo', markersize=10, marker='x', label='Max' if i == 0 else '')

ax.set_xticks(positions)
ax.set_xticklabels(endpoints, rotation=45, ha='right')
ax.set_ylabel('Tempo de Resposta (ms)')
ax.set_title('Distribui√ß√£o de Tempos de Resposta por Endpoint')
ax.legend(loc='upper left')
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('resultados/analise_outliers.png', dpi=300, bbox_inches='tight')
print("\n‚úÖ Gr√°fico de outliers salvo: resultados/analise_outliers.png")
plt.show()
```

**Execute e analise:**

```bash
python analise_outliers.py
```

**Quest√µes:**
1. Quais endpoints apresentam maior variabilidade?
2. H√° requisi√ß√µes muito mais lentas que a m√©dia (outliers)?
3. O que pode causar esses outliers?

---

## üìù Parte 5: Relat√≥rio Profissional (45 min)

### Exerc√≠cio 5.1: Gera√ß√£o de Relat√≥rio HTML

**Objetivo**: Criar um relat√≥rio profissional para apresentar os resultados.

Crie o script `gerar_relatorio.py`:

```python
import pandas as pd
from datetime import datetime

def gerar_relatorio_html(stats_csv, history_csv, output_file='relatorio_final.html'):
    """Gera relat√≥rio HTML profissional"""

    # Carregar dados
    stats_df = pd.read_csv(stats_csv)
    history_df = pd.read_csv(history_csv)

    # Preparar dados agregados
    total_row = stats_df[stats_df['Name'] == 'Aggregated'].iloc[0]
    endpoints_df = stats_df[stats_df['Name'] != 'Aggregated']

    total_requisicoes = int(total_row['Request Count'])
    total_falhas = int(total_row['Failure Count'])
    taxa_erro = (total_falhas / total_requisicoes * 100) if total_requisicoes > 0 else 0
    tempo_medio = total_row['Average Response Time']
    p95 = total_row['95%']
    p99 = total_row['99%']
    rps_medio = total_row['Requests/s']

    # Dura√ß√£o do teste
    history_df['Timestamp'] = pd.to_datetime(history_df['Timestamp'], unit='s')
    duracao = history_df['Timestamp'].max() - history_df['Timestamp'].min()

    # Determinar status geral
    status_geral = "‚úÖ APROVADO"
    cor_status = "green"
    if taxa_erro > 1:
        status_geral = "‚ùå REPROVADO"
        cor_status = "red"
    elif taxa_erro > 0.1 or p95 > 2000:
        status_geral = "‚ö†Ô∏è APROVADO COM RESSALVAS"
        cor_status = "orange"

    # Gerar tabela de endpoints
    endpoints_table = ""
    for idx, row in endpoints_df.iterrows():
        nome = row['Name']
        req = int(row['Request Count'])
        falhas = int(row['Failure Count'])
        erro_pct = (falhas / req * 100) if req > 0 else 0
        tempo_avg = row['Average Response Time']
        p50 = row['50%']
        p95_ep = row['95%']
        p99_ep = row['99%']
        min_time = row['Min Response Time']
        max_time = row['Max Response Time']

        cor_erro = 'green' if erro_pct < 0.5 else 'orange' if erro_pct < 2 else 'red'
        cor_tempo = 'green' if tempo_avg < 1000 else 'orange' if tempo_avg < 2000 else 'red'

        endpoints_table += f"""
        <tr>
            <td><strong>{nome}</strong></td>
            <td>{req:,}</td>
            <td>{falhas:,}</td>
            <td><span style="color: {cor_erro}; font-weight: bold;">{erro_pct:.2f}%</span></td>
            <td><span style="color: {cor_tempo};">{tempo_avg:.0f}ms</span></td>
            <td>{p50:.0f}ms</td>
            <td>{p95_ep:.0f}ms</td>
            <td>{p99_ep:.0f}ms</td>
            <td>{min_time:.0f}ms</td>
            <td>{max_time:.0f}ms</td>
        </tr>
        """

    # Template HTML
    html_content = f"""
    <!DOCTYPE html>
    <html lang="pt-BR">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Relat√≥rio de Teste de Performance - Locust</title>
        <style>
            * {{ margin: 0; padding: 0; box-sizing: border-box; }}
            body {{
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                padding: 20px;
                line-height: 1.6;
            }}
            .container {{
                max-width: 1200px;
                margin: 0 auto;
                background: white;
                padding: 40px;
                border-radius: 12px;
                box-shadow: 0 10px 40px rgba(0,0,0,0.3);
            }}
            header {{
                border-bottom: 4px solid #667eea;
                padding-bottom: 20px;
                margin-bottom: 30px;
            }}
            h1 {{
                color: #333;
                margin-bottom: 10px;
                font-size: 32px;
            }}
            .subtitle {{
                color: #666;
                font-size: 14px;
                margin-bottom: 5px;
            }}
            .status-badge {{
                display: inline-block;
                padding: 8px 16px;
                border-radius: 20px;
                font-weight: bold;
                margin: 10px 0;
                background: {cor_status};
                color: white;
                font-size: 16px;
            }}
            h2 {{
                color: #555;
                margin-top: 40px;
                margin-bottom: 20px;
                border-left: 5px solid #667eea;
                padding-left: 15px;
                font-size: 24px;
            }}
            .summary {{
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
                gap: 20px;
                margin: 30px 0;
            }}
            .card {{
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
                padding: 25px;
                border-radius: 12px;
                text-align: center;
                box-shadow: 0 4px 15px rgba(0,0,0,0.1);
                transition: transform 0.3s ease;
            }}
            .card:hover {{
                transform: translateY(-5px);
            }}
            .card.success {{ background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%); }}
            .card.error {{ background: linear-gradient(135deg, #eb3349 0%, #f45c43 100%); }}
            .card.warning {{ background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); }}
            .card.info {{ background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%); }}
            .card-value {{
                font-size: 36px;
                font-weight: bold;
                margin: 15px 0;
            }}
            .card-label {{
                font-size: 13px;
                opacity: 0.95;
                text-transform: uppercase;
                letter-spacing: 1px;
            }}
            table {{
                width: 100%;
                border-collapse: collapse;
                margin: 20px 0;
                box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            }}
            th {{
                background: #667eea;
                color: white;
                padding: 15px;
                text-align: left;
                font-weight: 600;
                font-size: 13px;
                text-transform: uppercase;
                letter-spacing: 0.5px;
            }}
            td {{
                padding: 12px 15px;
                border-bottom: 1px solid #e0e0e0;
            }}
            tr:hover {{
                background: #f5f7ff;
            }}
            .timestamp {{
                color: #999;
                font-size: 12px;
                text-align: right;
                margin-top: 40px;
                padding-top: 20px;
                border-top: 1px solid #e0e0e0;
            }}
            .criterios {{
                background: #f9f9f9;
                padding: 20px;
                border-radius: 8px;
                margin: 20px 0;
            }}
            .criterios ul {{
                list-style-position: inside;
                margin-left: 10px;
            }}
            .criterios li {{
                padding: 5px 0;
            }}
            .observacoes {{
                background: #fff3cd;
                border-left: 4px solid #ffc107;
                padding: 15px;
                margin: 20px 0;
                border-radius: 4px;
            }}
        </style>
    </head>
    <body>
        <div class="container">
            <header>
                <h1>üìä Relat√≥rio de Teste de Performance</h1>
                <p class="subtitle">Sistema testado com Locust</p>
                <p class="subtitle">Gerado em {datetime.now().strftime("%d/%m/%Y √†s %H:%M:%S")}</p>
                <div class="status-badge">{status_geral}</div>
            </header>

            <h2>Resumo Executivo</h2>
            <div class="summary">
                <div class="card info">
                    <div class="card-label">Total de Requisi√ß√µes</div>
                    <div class="card-value">{total_requisicoes:,}</div>
                </div>
                <div class="card error">
                    <div class="card-label">Falhas</div>
                    <div class="card-value">{total_falhas:,}</div>
                </div>
                <div class="card error">
                    <div class="card-label">Taxa de Erro</div>
                    <div class="card-value">{taxa_erro:.2f}%</div>
                </div>
                <div class="card success">
                    <div class="card-label">Tempo M√©dio</div>
                    <div class="card-value">{tempo_medio:.0f}ms</div>
                </div>
                <div class="card warning">
                    <div class="card-label">P95</div>
                    <div class="card-value">{p95:.0f}ms</div>
                </div>
                <div class="card warning">
                    <div class="card-label">P99</div>
                    <div class="card-value">{p99:.0f}ms</div>
                </div>
                <div class="card">
                    <div class="card-label">RPS M√©dio</div>
                    <div class="card-value">{rps_medio:.1f}</div>
                </div>
                <div class="card info">
                    <div class="card-label">Dura√ß√£o</div>
                    <div class="card-value">{duracao}</div>
                </div>
            </div>

            <h2>Crit√©rios de Aceita√ß√£o</h2>
            <div class="criterios">
                <ul>
                    <li>‚úÖ Response time m√©dio < 1000ms: <strong>{tempo_medio:.0f}ms</strong> {"‚úÖ" if tempo_medio < 1000 else "‚ùå"}</li>
                    <li>‚úÖ P95 < 2000ms: <strong>{p95:.0f}ms</strong> {"‚úÖ" if p95 < 2000 else "‚ùå"}</li>
                    <li>‚úÖ Taxa de erro < 0.1%: <strong>{taxa_erro:.2f}%</strong> {"‚úÖ" if taxa_erro < 0.1 else "‚ùå"}</li>
                </ul>
            </div>

            <h2>An√°lise por Endpoint</h2>
            <table>
                <thead>
                    <tr>
                        <th>Endpoint</th>
                        <th>Requisi√ß√µes</th>
                        <th>Falhas</th>
                        <th>Taxa Erro</th>
                        <th>M√©dia</th>
                        <th>P50</th>
                        <th>P95</th>
                        <th>P99</th>
                        <th>M√≠n</th>
                        <th>M√°x</th>
                    </tr>
                </thead>
                <tbody>
                    {endpoints_table}
                </tbody>
            </table>

            <h2>Observa√ß√µes e Recomenda√ß√µes</h2>
            <div class="observacoes">
                <p><strong>An√°lise Geral:</strong></p>
                <p>O sistema foi submetido a um teste de carga durante {duracao}.
                   Durante este per√≠odo, foram realizadas {total_requisicoes:,} requisi√ß√µes
                   com uma taxa de erro de {taxa_erro:.2f}%.</p>

                <p style="margin-top: 15px;"><strong>Recomenda√ß√µes:</strong></p>
                <ul>
                    {"<li>‚úÖ Sistema apresentou performance satisfat√≥ria</li>" if taxa_erro < 0.1 and tempo_medio < 1000 else ""}
                    {"<li>‚ö†Ô∏è Monitorar taxa de erro em produ√ß√£o</li>" if taxa_erro > 0.1 else ""}
                    {"<li>‚ö†Ô∏è Considerar otimiza√ß√£o de endpoints lentos</li>" if p95 > 2000 else ""}
                    {"<li>‚ö†Ô∏è Investigar causa das falhas</li>" if total_falhas > 0 else ""}
                </ul>
            </div>

            <div class="timestamp">
                <p>Relat√≥rio gerado automaticamente por Locust</p>
                <p>Data: {datetime.now().isoformat()}</p>
            </div>
        </div>
    </body>
    </html>
    """

    # Salvar arquivo
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(html_content)

    print(f"‚úÖ Relat√≥rio HTML gerado com sucesso: {output_file}")
    return output_file

# Executar
gerar_relatorio_html(
    'resultados/teste_alta_carga_stats.csv',
    'resultados/teste_alta_carga_stats_history.csv',
    'resultados/relatorio_final.html'
)
```

**Execute:**

```bash
python gerar_relatorio.py
```

**Abra o relat√≥rio no navegador:**

```bash
# Linux/Mac
open resultados/relatorio_final.html

# Windows
start resultados/relatorio_final.html
```

---

## üéì Parte 6: Projeto Final - Avalia√ß√£o (60 min)

### Projeto: An√°lise Completa de Performance

**Objetivo**: Realizar uma an√°lise completa de performance de uma API, documentando todos os passos e resultados.

**Requisitos:**

1. **Executar 3 tipos de teste**:
   - Teste de carga (100-300 usu√°rios)
   - Teste de stress (at√© encontrar limite)
   - Teste de pico (escalada r√°pida)

2. **Exportar todos os dados**:
   - CSV de todos os testes
   - HTML reports
   - Logs de execu√ß√£o

3. **An√°lise completa**:
   - M√©tricas principais de cada teste
   - Compara√ß√£o entre os 3 testes
   - Identifica√ß√£o de gargalos
   - An√°lise de outliers

4. **Visualiza√ß√µes**:
   - Gr√°ficos de evolu√ß√£o temporal
   - Compara√ß√£o de performance
   - Distribui√ß√£o de percentis

5. **Relat√≥rio final**:
   - Relat√≥rio HTML profissional
   - Conclus√µes e recomenda√ß√µes
   - Status de aprova√ß√£o/reprova√ß√£o

**Entreg√°veis:**

```
projeto_final/
‚îú‚îÄ‚îÄ locustfile.py
‚îú‚îÄ‚îÄ README.md (documenta√ß√£o do projeto)
‚îú‚îÄ‚îÄ testes/
‚îÇ   ‚îú‚îÄ‚îÄ teste_carga.sh
‚îÇ   ‚îú‚îÄ‚îÄ teste_stress.sh
‚îÇ   ‚îî‚îÄ‚îÄ teste_pico.sh
‚îú‚îÄ‚îÄ resultados/
‚îÇ   ‚îú‚îÄ‚îÄ teste_carga_*
‚îÇ   ‚îú‚îÄ‚îÄ teste_stress_*
‚îÇ   ‚îî‚îÄ‚îÄ teste_pico_*
‚îú‚îÄ‚îÄ analises/
‚îÇ   ‚îú‚îÄ‚îÄ analise_basica.py
‚îÇ   ‚îú‚îÄ‚îÄ analise_comparativa.py
‚îÇ   ‚îú‚îÄ‚îÄ analise_outliers.py
‚îÇ   ‚îî‚îÄ‚îÄ gerar_relatorio.py
‚îî‚îÄ‚îÄ relatorio_final.html
```

**Crit√©rios de avalia√ß√£o:**

| Crit√©rio                        | Peso |
| ------------------------------- | ---- |
| Execu√ß√£o correta dos 3 testes   | 20%  |
| Exporta√ß√£o completa dos dados   | 15%  |
| An√°lise de m√©tricas             | 25%  |
| Qualidade das visualiza√ß√µes     | 20%  |
| Relat√≥rio final e conclus√µes    | 20%  |

---

## üìö Recursos Adicionais

### Scripts Auxiliares

**1. Script de limpeza:**

```bash
#!/bin/bash
# limpar_resultados.sh
echo "Limpando resultados antigos..."
rm -rf resultados/*
mkdir -p resultados
echo "‚úÖ Pasta de resultados limpa"
```

**2. Script de backup:**

```bash
#!/bin/bash
# backup_resultados.sh
DATA=$(date +%Y%m%d_%H%M%S)
echo "Fazendo backup dos resultados..."
tar -czf backup_$DATA.tar.gz resultados/
echo "‚úÖ Backup criado: backup_$DATA.tar.gz"
```

### Comandos √öteis

```bash
# Ver tamanho dos arquivos de resultados
du -sh resultados/*

# Contar n√∫mero de linhas em um CSV
wc -l resultados/*.csv

# Ver √∫ltimas linhas do hist√≥rico
tail -n 20 resultados/*_history.csv

# Procurar por erros espec√≠ficos
grep -i "error" resultados/*.csv
```

### Checklist de Execu√ß√£o

- [ ] Ambiente Python configurado
- [ ] Locust instalado e atualizado
- [ ] Depend√™ncias instaladas (pandas, matplotlib, seaborn)
- [ ] Pasta de resultados criada
- [ ] Locustfile testado e validado
- [ ] Scripts de an√°lise preparados
- [ ] Testes executados com sucesso
- [ ] Dados exportados corretamente
- [ ] An√°lises realizadas
- [ ] Visualiza√ß√µes geradas
- [ ] Relat√≥rio final criado
- [ ] Projeto documentado

---

## üèÅ Conclus√£o

Ao final deste roteiro, voc√™ deve ser capaz de:

1. ‚úÖ Exportar dados de testes Locust de m√∫ltiplas formas
2. ‚úÖ Analisar m√©tricas de performance com Python/Pandas
3. ‚úÖ Criar visualiza√ß√µes profissionais dos resultados
4. ‚úÖ Comparar resultados de diferentes testes
5. ‚úÖ Identificar gargalos e outliers
6. ‚úÖ Gerar relat√≥rios profissionais em HTML
7. ‚úÖ Documentar e apresentar resultados de forma clara

---

**D√∫vidas?**
- Consulte a documenta√ß√£o oficial do Locust: https://docs.locust.io
- Revise o documento de exporta√ß√£o: `exportacao_locust.md`
- Consulte o documento de tipos de teste: `tipo_teste_locust.md`

**Boa sorte com os testes!** üöÄ
